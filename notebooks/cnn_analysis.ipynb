{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this step first, if your work-directory isn't the main folder (nuclide-identification)\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "os.chdir(parent_dir)\n",
    "print(f\"Directory changed to: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import src.measurements.api as mpi\n",
    "import src.peaks.api as ppi\n",
    "from src.cnn.training import Training\n",
    "import json\n",
    "import mlflow\n",
    "import os\n",
    "from config.loader import load_config\n",
    "\n",
    "plt.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = load_config()[\"minio\"][\"AWS_ACCESS_KEY_ID\"]\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = load_config()[\"minio\"][\"AWS_SECRET_ACCESS_KEY\"]\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = load_config()[\"minio\"][\"MLFLOW_S3_ENDPOINT_URL\"]\n",
    "model_uri = load_config()[\"mlflow\"][\"uri\"]\n",
    "model_name = \"CNN_CPU\"\n",
    "model_version = \"latest\"\n",
    "mlflow.set_tracking_uri(uri=model_uri)\n",
    "model = mlflow.pytorch.load_model(f\"models:/{model_name}/{model_version}\").to(\"cpu\")\n",
    "\n",
    "client = mlflow.tracking.MlflowClient(\n",
    "    tracking_uri=load_config()[\"mlflow\"][\"uri\"]\n",
    ")\n",
    "run_id = client.get_latest_versions(\"CNN_CPU\")[0].run_id\n",
    "run_id = \"e78098da07bb482aa6b451bd7c6fc310\"\n",
    "run = client.get_run(run_id)\n",
    "client.download_artifacts(run_id=run_id, path=\"artifacts.json\", dst_path=\"tmp\")\n",
    "mlb_classes = run.data.params[\"mlb_classes\"].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_macro_loss = client.get_metric_history(run_id=run_id, key=\"training_macro_loss\")\n",
    "training_micro_loss = client.get_metric_history(run_id=run_id, key=\"training_micro_loss\")\n",
    "training_mac_loss = []\n",
    "training_mic_loss = []\n",
    "\n",
    "validation_macro_loss = client.get_metric_history(run_id=run_id, key=\"validation_macro_loss\")\n",
    "validation_mac_loss = []\n",
    "validation_mic_loss = []\n",
    "for i in range(len(training_macro_loss)):\n",
    "    macro_loss = training_macro_loss[i].value\n",
    "    training_mac_loss.append(macro_loss)\n",
    "    micro_loss = training_micro_loss[i].value\n",
    "    training_mic_loss.append(micro_loss)\n",
    "\n",
    "    val_macro_loss = validation_macro_loss[i].value\n",
    "    validation_mac_loss.append(val_macro_loss)\n",
    "\n",
    "data_mic_mac_loss = pd.DataFrame([training_mac_loss, training_mic_loss, validation_mac_loss])\n",
    "data_mic_mac_loss = data_mic_mac_loss.T.rename(columns={0: \"training_macro_loss\", 1: \"training_micro_loss\",\n",
    "                                                        2: \"validation_macro_loss\"})\n",
    "data_mic_mac_loss[\"epoch\"] = data_mic_mac_loss.index\n",
    "data_mic_mac_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tmp/artifacts.json\") as f:\n",
    "    artifacts = json.load(f)\n",
    "\n",
    "data_tpr_fpr = pd.DataFrame()\n",
    "\n",
    "for idx in range(len(artifacts[\"validation_tpr\"])):\n",
    "    for nuclide in artifacts[\"validation_tpr\"][idx].keys():\n",
    "        nuclide_df = pd.DataFrame(artifacts[\"validation_tpr\"][idx][nuclide], columns=[\"validation_tpr\"])\n",
    "        nuclide_df[\"validation_fpr\"] = artifacts[\"validation_fpr\"][idx][nuclide]\n",
    "        nuclide_df[\"nuclide\"] = nuclide\n",
    "        nuclide_df[\"epoch\"] = idx\n",
    "        data_tpr_fpr = pd.concat([data_tpr_fpr, nuclide_df], axis=0)\n",
    "data_tpr_fpr = data_tpr_fpr.reset_index(drop=True)\n",
    "\n",
    "data_auc = pd.DataFrame()\n",
    "\n",
    "for idx in range(len(artifacts[\"training_auc\"])):\n",
    "    for nuclide in artifacts[\"training_auc\"][idx].keys():\n",
    "        nuclide_df = pd.DataFrame([artifacts[\"training_auc\"][idx][nuclide]], columns=[\"training_auc\"])\n",
    "        nuclide_df[\"validation_auc\"] = artifacts[\"validation_auc\"][idx][nuclide]\n",
    "        nuclide_df[\"nuclide\"] = nuclide\n",
    "        nuclide_df[\"epoch\"] = idx\n",
    "        data_auc = pd.concat([data_auc, nuclide_df], axis=0)\n",
    "data_auc = data_auc.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=data_auc, x=\"epoch\", y=\"validation_auc\", hue=\"nuclide\", kind=\"line\", palette=sns.color_palette(),\n",
    "            alpha=0.2)\n",
    "plt.plot(data_mic_mac_loss[\"epoch\"], data_mic_mac_loss[\"training_macro_loss\"], color=\"black\",\n",
    "         label=\"training_macro_loss\")\n",
    "\n",
    "plt.plot(data_mic_mac_loss[\"epoch\"], data_mic_mac_loss[\"validation_macro_loss\"], color=\"red\",\n",
    "         label=\"validation_macro_loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_keys = mpi.API().re_splitted_keys()\n",
    "re_keys = re_keys.loc[re_keys[\"type\"] == \"cnn_validation\"]\n",
    "re_keys = re_keys[\"datetime\"].tolist()\n",
    "validation_set = ppi.API().re_measurement(re_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_isotope(isotope):\n",
    "    match = re.match(r\"([a-zA-Z]+)(\\d+)\", isotope)\n",
    "    if match:\n",
    "        element, mass = match.groups()\n",
    "        return f\"$^{{{mass}}}{element.capitalize()}$\"\n",
    "    else:\n",
    "        return isotope\n",
    "\n",
    "\n",
    "def __identify_background(data, wndw: int = 5, scale: float = 1.5) -> np.ndarray:\n",
    "    data = data.sort_index()\n",
    "    data[\"count\"] = data[\"count\"].astype(float)\n",
    "    counts = data[\"count\"].values\n",
    "    slopes = np.abs(np.diff(counts))\n",
    "    moving_avg = np.convolve(slopes, np.ones(wndw) / wndw, mode=\"same\")\n",
    "    threshold = np.mean(moving_avg) * scale\n",
    "    background_mask = moving_avg < threshold\n",
    "    background_mask = np.append(\n",
    "        background_mask, True\n",
    "    )\n",
    "    background = np.interp(\n",
    "        np.arange(len(counts)),\n",
    "        np.arange(len(counts))[background_mask],\n",
    "        counts[background_mask],\n",
    "    )\n",
    "    return background\n",
    "\n",
    "\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "\n",
    "def make_subplot(ax, one_meas_processed_measurement, limitation, idx, title, scaler):\n",
    "    meas_500 = one_meas_processed_measurement.loc[one_meas_processed_measurement[\"energy\"] > 0]\n",
    "    meas_500[\"background\"] = __identify_background(meas_500)\n",
    "    meas_500[\"counts_cleaned\"] = meas_500[\"count\"] - meas_500[\"background\"]\n",
    "    ax.plot(meas_500[\"energy\"], meas_500[\"count\"], label=\"Gemessene $\\gamma$-Spektren\", color=sns.color_palette()[0],\n",
    "            alpha=1,\n",
    "            linewidth=0.5)\n",
    "\n",
    "    colors = sns.color_palette(\"dark\")\n",
    "    color_idx = 0\n",
    "    colors_dict = {}\n",
    "    last_x = 0\n",
    "    already_annotated = False\n",
    "    for _, row in meas_500[meas_500[\"peak\"] == True].iterrows():\n",
    "        x = row[\"energy\"]\n",
    "        label = row[\"identified_isotope\"]\n",
    "        if label in colors_dict.keys():\n",
    "            color = colors_dict[label]\n",
    "            already_annotated = True\n",
    "        else:\n",
    "            color = colors[color_idx]\n",
    "            colors_dict[label] = color\n",
    "            color_idx += 1\n",
    "            already_annotated = False\n",
    "        if x - last_x < 100 and last_x > 0:\n",
    "            space = x * scaler\n",
    "        else:\n",
    "            space = 0\n",
    "\n",
    "        last_x = x\n",
    "        ax.vlines(\n",
    "            x=x,\n",
    "            ymin=0,\n",
    "            ymax=1_000_000,\n",
    "            color=color,\n",
    "            alpha=0.5,\n",
    "            linewidth=0.3,\n",
    "            linestyle=(0, (5, 5))\n",
    "        )\n",
    "        if already_annotated is True:\n",
    "            pass\n",
    "        else:\n",
    "            ax.annotate(\n",
    "                text=label,\n",
    "                xy=(x, limitation),\n",
    "                xytext=(x + space, limitation * 1.15),\n",
    "                textcoords='data',\n",
    "                fontsize=11,\n",
    "                color=color,\n",
    "                rotation=90,\n",
    "                zorder=0,\n",
    "                ha='left',\n",
    "                va='bottom',\n",
    "                arrowprops=dict(\n",
    "                    arrowstyle='-',\n",
    "                    connectionstyle='arc,angleA=90,angleB=0,rad=0,armA=10,armB=0',\n",
    "                    color=color,\n",
    "                    linewidth=0.3,\n",
    "                    zorder=100,\n",
    "                    linestyle=(0, (5, 5)),\n",
    "                    alpha=0.5\n",
    "                )\n",
    "            )\n",
    "\n",
    "    ax.text(1.02, 0.6, title,\n",
    "            transform=ax.transAxes,\n",
    "            rotation=270,\n",
    "            va='center',\n",
    "            zorder=2000,\n",
    "            ha='left',\n",
    "            fontsize=12)\n",
    "    ax.set_ylim(0, limitation)\n",
    "    ax.set_xlim(0, 2000)\n",
    "    ax.tick_params(axis='x', labelsize=12, bottom=True)\n",
    "    ax.tick_params(axis='y', labelsize=12, left=True)\n",
    "    ax.grid(False)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.set_xticks([0, 500, 1000, 1500, 2000])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(10, 5), sharex=True)\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "good_examples = [0, 20, 40, 58, 75, 109]\n",
    "axs = axs.flatten()\n",
    "\n",
    "fig.text(0.5, 0.0, \"Energie [keV]\", size=14, ha='center')\n",
    "fig.text(0.05, 0.5, \"Zählwert\", size=14, va='center', rotation='vertical')\n",
    "limitations = [50, 300, 500, 1000, 60, 2000]\n",
    "scaler = [10, 10, 10, 0.0, 0.2, 10]\n",
    "titles = [\"(A) 1 Nuklid\", \"(B) 2 Nuklide\", \"(C) 3 Nuklide\",\n",
    "          \"(D) 4 Nuklide\", \"(E) 5 Nuklide\", \"(F) 6 Nuklide\"]\n",
    "for idx, sample in enumerate(good_examples):\n",
    "    date = re_keys[sample]\n",
    "    limitation = limitations[idx]\n",
    "    one_meas_processed_measurement = validation_set.loc[validation_set[\"datetime\"] == date]\n",
    "    one_meas_processed_measurement[\"identified_isotope\"] = one_meas_processed_measurement[\"identified_isotope\"].apply(\n",
    "        format_isotope)\n",
    "    make_subplot(axs[idx], one_meas_processed_measurement, limitation, idx, titles[idx], scaler[idx])\n",
    "\n",
    "handles_labels = [axs[i].get_legend_handles_labels() for i in range(len(axs))]\n",
    "handles, labels = [], []\n",
    "for h, l in handles_labels:\n",
    "    for handle, label in zip(h, l):\n",
    "        if label not in labels:\n",
    "            handles.append(handle)\n",
    "            labels.append(label)\n",
    "leg = fig.legend(\n",
    "    handles, labels,\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.5, -0.05),\n",
    "    ncol=2,\n",
    "    fontsize=12,\n",
    "    frameon=False\n",
    ")\n",
    "for line in leg.get_lines():\n",
    "    line.set_linewidth(3)\n",
    "plt.savefig(\"plots/background_meas_example555.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for key in re_keys[8:9]:\n",
    "    filtered_df = validation_set.loc[validation_set[\"datetime\"] == key].reset_index(drop=True)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=filtered_df[\"energy\"],\n",
    "        y=filtered_df[\"count\"],\n",
    "        mode='lines',\n",
    "        name=str(key),\n",
    "        line=dict(color='black')\n",
    "    ))\n",
    "    identified_peaks = filtered_df.loc[filtered_df[\"peak\"] == True].reset_index(drop=True)\n",
    "    unique_isotopes = identified_peaks[\"identified_isotope\"].unique()\n",
    "    for iso in unique_isotopes:\n",
    "        filtered_iso = identified_peaks.loc[identified_peaks[\"identified_isotope\"] == iso].reset_index(drop=True)\n",
    "        fig.add_trace(go.Scatter(x=filtered_iso[\"energy\"], y=filtered_iso[\"count\"],\n",
    "                                 mode='markers', name=iso,\n",
    "                                 marker=dict(color='red', size=8, symbol='circle')))\n",
    "\n",
    "fig.update_layout(height=1000, title=\"Signal mit Peaks\")\n",
    "fig.update_xaxes(title=\"Energie [keV]\")\n",
    "fig.update_yaxes(title=\"Zählwert\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "training_min_loss_x = data_mic_mac_loss[\"training_macro_loss\"].max()\n",
    "training_min_loss_y = \\\n",
    "data_mic_mac_loss.loc[data_mic_mac_loss[\"training_macro_loss\"] == training_min_loss_x][\"epoch\"].values[0]\n",
    "\n",
    "validation_min_loss_x = data_mic_mac_loss[\"validation_macro_loss\"].max()\n",
    "validation_min_loss_y = \\\n",
    "data_mic_mac_loss.loc[data_mic_mac_loss[\"validation_macro_loss\"] == validation_min_loss_x][\"epoch\"].values[0]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(data_mic_mac_loss[\"epoch\"], data_mic_mac_loss[\"training_macro_loss\"], color=\"black\",\n",
    "         label=\"training_macro_loss\")\n",
    "\n",
    "plt.plot(data_mic_mac_loss[\"epoch\"], data_mic_mac_loss[\"validation_macro_loss\"], color=\"red\",\n",
    "         label=\"validation_macro_loss\")\n",
    "plt.annotate(f'MAX(Macro-AUC) Training = {round(training_min_loss_x, 2)}',\n",
    "             ha='center', va='bottom',\n",
    "             size='large',\n",
    "             xytext=(training_min_loss_y, 1), xy=(training_min_loss_y, training_min_loss_x),\n",
    "             arrowprops={'facecolor': 'darkgrey'}, alpha=0.5)\n",
    "\n",
    "plt.annotate(f'MAX(Macro-AUC) Validierung = {round(validation_min_loss_x, 2)}',\n",
    "             ha='center', va='bottom',\n",
    "             size='large',\n",
    "             xytext=(validation_min_loss_y, 1), xy=(validation_min_loss_y, validation_min_loss_x),\n",
    "             arrowprops={'facecolor': 'darkgrey'}, alpha=0.5)\n",
    "plt.ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = data_auc.loc[data_auc[\"epoch\"] == validation_min_loss_y]\n",
    "\n",
    "\n",
    "def format_isotope(isotope):\n",
    "    match = re.match(r\"([a-zA-Z]+)(\\d+)\", isotope)\n",
    "    if match:\n",
    "        element, mass = match.groups()\n",
    "        validation_auc = aucs.loc[aucs[\"nuclide\"] == isotope].reset_index(drop=True)[\"validation_auc\"][0]\n",
    "        training_uac = aucs.loc[aucs[\"nuclide\"] == isotope].reset_index(drop=True)[\"training_auc\"][0]\n",
    "        return f\"$^{{{mass}}}{element.capitalize()}$\\nAUC-Training={round(training_uac, 2)}\\nAUC-Validation={round(validation_auc, 2)}\"\n",
    "    else:\n",
    "        return isotope\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "filtered_data = data_tpr_fpr[data_tpr_fpr[\"epoch\"] == validation_min_loss_y].reset_index(drop=True)\n",
    "filtered_data[\"nuclide\"] = filtered_data[\"nuclide\"].apply(format_isotope)\n",
    "rel = sns.relplot(filtered_data, x=\"validation_fpr\", y=\"validation_tpr\", hue=\"nuclide\", kind=\"line\",\n",
    "                  drawstyle=\"steps-pre\", palette=sns.color_palette())\n",
    "ax = rel.ax\n",
    "ax.plot([0, 1], [0, 1], color=\"lightgrey\", linestyle=\"--\", linewidth=2, label=\"Basislinie\")\n",
    "ax.set_xlabel(\"False Positive Rate (FPR)\", size=14)\n",
    "ax.set_ylabel(\"True Positive Rate (TPR)\", size=14)\n",
    "ax.tick_params(axis='x', labelsize=12, bottom=True)\n",
    "ax.tick_params(axis='y', labelsize=12, left=True)\n",
    "ax.grid(True, alpha=0.2)\n",
    "sns.move_legend(rel,\n",
    "                loc=\"lower center\",\n",
    "                bbox_to_anchor=(0.5, 1.02),\n",
    "                borderaxespad=0,\n",
    "                title=\"\",\n",
    "                ncol=3,\n",
    "                frameon=False)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "rel._legend.remove()\n",
    "ax.legend(handles, labels, loc=\"lower center\", bbox_to_anchor=(0.5, 1.02), ncol=3, frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.measurements.api as mpi\n",
    "\n",
    "splitted_keys = mpi.API().re_splitted_keys()\n",
    "validation_keys = splitted_keys.loc[splitted_keys[\"type\"] == \"cnn_validation\"].reset_index(drop=True)[\n",
    "    \"datetime\"].tolist()\n",
    "validation_measurements = ppi.API().re_measurement(validation_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_cnn_pm = Training(use_processed_synthetics=bool(\n",
    "    load_config()[\"cnn\"][\"use_processed_synthetics\"]\n",
    "),\n",
    "    use_processed_measuremnets=bool(\n",
    "        load_config()[\"cnn\"][\"use_processed_measurements\"],\n",
    "    ),\n",
    "    use_re_processed_data=True).validation_cnn_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_mlb = validation_cnn_pm.fitted_mlb\n",
    "fitted_mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "isos_ind = pd.DataFrame([validation_cnn_pm.labels_by_datetime]).T.reset_index()\n",
    "import re\n",
    "\n",
    "\n",
    "def count_ones(val):\n",
    "    arr = val\n",
    "    return sum(arr[0])\n",
    "\n",
    "\n",
    "isos_ind[\"ones_count\"] = isos_ind[0].apply(count_ones)\n",
    "isos_ind.groupby(\"ones_count\")[\"index\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "validation_cnn_pm_loader = DataLoader(\n",
    "    validation_cnn_pm, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = validation_cnn_pm.__getitem__(10)\n",
    "test = item[0].float().to(\"cpu\").unsqueeze(0).unsqueeze(0)\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlb_classes\n",
    "model.eval()\n",
    "for i in range(30):\n",
    "    item = validation_cnn_pm.__getitem__(i)\n",
    "    test = item[0].float().to(\"cpu\").unsqueeze(0).unsqueeze(0)\n",
    "    output = model(test)\n",
    "    print(torch.sigmoid(output))\n",
    "    print(item[0])\n",
    "    print(item[2])\n",
    "    print(item[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 8160 * 0.34507313512321336, 0.34507313512321336)\n",
    "plt.plot(x, test[0].T)\n",
    "\n",
    "plt.ylim(0, 0.1)\n",
    "plt.xlim(0, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks, savgol_filter\n",
    "\n",
    "target = torch.tensor([item[2].T])\n",
    "\n",
    "test.requires_grad_()\n",
    "output = model(test)\n",
    "\n",
    "positive_classes = (target[0] == 1).nonzero(as_tuple=True)[0]\n",
    "\n",
    "for class_idx in positive_classes:\n",
    "    model.zero_grad()\n",
    "    print(class_idx)\n",
    "\n",
    "    class_score = output[0, class_idx]\n",
    "    class_score.backward(retain_graph=True)\n",
    "\n",
    "    saliency = test.grad.data.abs()\n",
    "    saliency, _ = saliency.max(dim=1)\n",
    "    saliency_map = saliency.squeeze().cpu().numpy()\n",
    "\n",
    "    saliency_map -= saliency_map.min()\n",
    "    saliency_map /= saliency_map.max() + 1e-8\n",
    "\n",
    "    plt.plot(x, savgol_filter(saliency_map, window_length=100, polyorder=1))\n",
    "    plt.title(f\"Saliency Map for Class {class_idx.item()}\")\n",
    "    plt.show()\n",
    "\n",
    "    test.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "model.eval()\n",
    "background = []\n",
    "for i in range(30):\n",
    "    item = validation_cnn_pm.__getitem__(i)\n",
    "    test = item[0].float().to(\"cpu\").unsqueeze(0).unsqueeze(0)\n",
    "    background.append(test)\n",
    "    output = model(test)\n",
    "    print(torch.sigmoid(output))\n",
    "    print(item[0])\n",
    "    print(item[2])\n",
    "    print(item[1])\n",
    "background = torch.cat(background, dim=0)\n",
    "explainer = shap.DeepExplainer(model, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ModelWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model.eval().to(\"cuda\")\n",
    "\n",
    "    def __call__(self, x_numpy):\n",
    "        x_tensor = torch.from_numpy(x_numpy).float().unsqueeze(1).to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            return torch.sigmoid(self.model(x_tensor)).cpu().numpy()\n",
    "\n",
    "\n",
    "validation_cnn_pm_loader = DataLoader(validation_cnn_pm, batch_size=50, shuffle=True)\n",
    "batch = next(iter(validation_cnn_pm_loader))[0]\n",
    "\n",
    "background = batch[:20].numpy()\n",
    "test_sample = batch[21].unsqueeze(0).numpy()\n",
    "wrapped_model = ModelWrapper(model)\n",
    "explainer = shap.Explainer(wrapped_model, background, algorithm=\"partition\")\n",
    "shap_values = explainer(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "shap_vals_class0 = shap_values.values[0, :, 0]\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "x = np.arange(0, 8160 * 0.34507313512321336, 0.34507313512321336)\n",
    "plt.plot(x, shap_vals_class0)\n",
    "plt.title(\"SHAP values for class 1\")\n",
    "plt.xlabel(\"Feature index\")\n",
    "plt.ylabel(\"SHAP value\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
