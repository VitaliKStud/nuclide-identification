{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import random\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import matplotlib\n",
    "import matplotlib.colors as mcolors\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "from src.peaks.finder import PeakFinder\n",
    "\n",
    "import mlflow\n",
    "from config.loader import load_config\n",
    "import os\n",
    "\n",
    "import src.measurements.api as mpi\n",
    "import src.generator.api as gpi\n",
    "import src.peaks.api as ppi\n",
    "import src.statistics.api as spi\n",
    "plt.rcParams['text.usetex'] = True\n",
    "from src.cnn.training import Training\n",
    "import json\n",
    "from src.cnn.dataset import MeasurementTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_latest_versions(\"CNN_CPU\")[0].run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "from config.loader import load_config\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = load_config()[\"minio\"][\"AWS_ACCESS_KEY_ID\"]\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = load_config()[\"minio\"][\"AWS_SECRET_ACCESS_KEY\"]\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = load_config()[\"minio\"][\"MLFLOW_S3_ENDPOINT_URL\"]\n",
    "model_uri = load_config()[\"mlflow\"][\"uri\"]\n",
    "model_name = \"CNN_CPU\"\n",
    "model_version = \"latest\"\n",
    "mlflow.set_tracking_uri(uri=model_uri)\n",
    "model = mlflow.pytorch.load_model(f\"models:/{model_name}/{model_version}\").to(\"cpu\")\n",
    "\n",
    "client = mlflow.tracking.MlflowClient(\n",
    "    tracking_uri=load_config()[\"mlflow\"][\"uri\"]\n",
    ")\n",
    "run_id = client.get_latest_versions(\"CNN_CPU\")[0].run_id\n",
    "# MODEL REAL MEASUREMENTS ONLY\n",
    "run_id = \"e78098da07bb482aa6b451bd7c6fc310\"\n",
    "run = client.get_run(run_id)\n",
    "client.download_artifacts(run_id=run_id, path=\"artifacts.json\", dst_path=\"tmp\")\n",
    "mlb_classes = run.data.params[\"mlb_classes\"].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_macro_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_macro_loss = client.get_metric_history(run_id=run_id, key=\"training_macro_loss\")\n",
    "training_micro_loss = client.get_metric_history(run_id=run_id, key=\"training_micro_loss\")\n",
    "training_mac_loss = []\n",
    "training_mic_loss = []\n",
    "\n",
    "validation_macro_loss = client.get_metric_history(run_id=run_id, key=\"validation_macro_loss\")\n",
    "validation_mac_loss = []\n",
    "validation_mic_loss = []\n",
    "for i in range(len(training_macro_loss)):\n",
    "    macro_loss = training_macro_loss[i].value\n",
    "    training_mac_loss.append(macro_loss)\n",
    "    micro_loss = training_micro_loss[i].value\n",
    "    training_mic_loss.append(micro_loss)\n",
    "\n",
    "    val_macro_loss = validation_macro_loss[i].value\n",
    "    validation_mac_loss.append(val_macro_loss)\n",
    "\n",
    "\n",
    "data_mic_mac_loss = pd.DataFrame([training_mac_loss, training_mic_loss, validation_mac_loss])\n",
    "data_mic_mac_loss = data_mic_mac_loss.T.rename(columns={0:\"training_macro_loss\", 1:\"training_micro_loss\",\n",
    "                                                        2:\"validation_macro_loss\"})\n",
    "data_mic_mac_loss[\"epoch\"] = data_mic_mac_loss.index\n",
    "data_mic_mac_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tmp/artifacts.json\") as f:\n",
    "    artifacts = json.load(f)\n",
    "# dict_keys(['used_keys', 'training_tpr', 'training_fpr', 'training_auc', 'validation_tpr', 'validation_fpr', 'validation_auc'])\n",
    "\n",
    "data_tpr_fpr = pd.DataFrame()\n",
    "\n",
    "for idx in range(len(artifacts[\"validation_tpr\"])):\n",
    "    for nuclide in artifacts[\"validation_tpr\"][idx].keys():\n",
    "        nuclide_df = pd.DataFrame(artifacts[\"validation_tpr\"][idx][nuclide], columns=[\"validation_tpr\"])\n",
    "        nuclide_df[\"validation_fpr\"] = artifacts[\"validation_fpr\"][idx][nuclide]\n",
    "        nuclide_df[\"nuclide\"] = nuclide\n",
    "        nuclide_df[\"epoch\"] = idx\n",
    "        data_tpr_fpr = pd.concat([data_tpr_fpr, nuclide_df], axis=0)\n",
    "data_tpr_fpr = data_tpr_fpr.reset_index(drop=True)\n",
    "\n",
    "data_auc = pd.DataFrame()\n",
    "\n",
    "for idx in range(len(artifacts[\"training_auc\"])):\n",
    "    for nuclide in artifacts[\"training_auc\"][idx].keys():\n",
    "        nuclide_df = pd.DataFrame([artifacts[\"training_auc\"][idx][nuclide]], columns=[\"training_auc\"])\n",
    "        nuclide_df[\"validation_auc\"] = artifacts[\"validation_auc\"][idx][nuclide]\n",
    "        nuclide_df[\"nuclide\"] = nuclide\n",
    "        nuclide_df[\"epoch\"] = idx\n",
    "        data_auc = pd.concat([data_auc, nuclide_df], axis=0)\n",
    "data_auc = data_auc.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=data_auc, x=\"epoch\", y=\"validation_auc\", hue=\"nuclide\", kind=\"line\", palette=sns.color_palette(), alpha=0.2)\n",
    "plt.plot(data_mic_mac_loss[\"epoch\"], data_mic_mac_loss[\"training_macro_loss\"], color=\"black\",\n",
    "         label=\"training_macro_loss\")\n",
    "\n",
    "plt.plot(data_mic_mac_loss[\"epoch\"], data_mic_mac_loss[\"validation_macro_loss\"], color=\"red\",\n",
    "         label=\"validation_macro_loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_keys = mpi.API().re_splitted_keys()\n",
    "re_keys = re_keys.loc[re_keys[\"type\"] == \"cnn_validation\"]\n",
    "re_keys = re_keys[\"datetime\"].tolist()\n",
    "validation_set = ppi.API().re_measurement(re_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_isotope(isotope):\n",
    "    match = re.match(r\"([a-zA-Z]+)(\\d+)\", isotope)\n",
    "    if match:\n",
    "        element, mass = match.groups()\n",
    "        return f\"$^{{{mass}}}{element.capitalize()}$\"\n",
    "    else:\n",
    "        return isotope  # fallback if format doesn't match\n",
    "\n",
    "def __identify_background(data, wndw: int = 5, scale: float = 1.5) -> np.ndarray:\n",
    "    data = data.sort_index()\n",
    "    data[\"count\"] = data[\"count\"].astype(float)\n",
    "    counts = data[\"count\"].values\n",
    "    slopes = np.abs(np.diff(counts))\n",
    "    moving_avg = np.convolve(slopes, np.ones(wndw) / wndw, mode=\"same\")\n",
    "    threshold = np.mean(moving_avg) * scale\n",
    "    background_mask = moving_avg < threshold\n",
    "    background_mask = np.append(\n",
    "        background_mask, True\n",
    "    )  # Ensure the mask has the same length as counts\n",
    "    background = np.interp(\n",
    "        np.arange(len(counts)),\n",
    "        np.arange(len(counts))[background_mask],\n",
    "        counts[background_mask],\n",
    "    )\n",
    "    return background\n",
    "\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "\n",
    "def make_subplot(ax, one_meas_processed_measurement, limitation, idx, title, scaler):\n",
    "    meas_500 = one_meas_processed_measurement.loc[one_meas_processed_measurement[\"energy\"] > 0]\n",
    "    meas_500[\"background\"] = __identify_background(meas_500)\n",
    "    meas_500[\"counts_cleaned\"] = meas_500[\"count\"] - meas_500[\"background\"]\n",
    "    ax.plot(meas_500[\"energy\"], meas_500[\"count\"], label=\"Messung\", color=sns.color_palette()[0], alpha=1,\n",
    "            linewidth=0.5)\n",
    "    # ax.plot(meas_500[\"energy\"], meas_500[\"background\"], label=\"Hintergrund\", color=sns.color_palette()[0], alpha=1,\n",
    "    #         linewidth=0.5, zorder=0)\n",
    "\n",
    "    colors = sns.color_palette(\"dark\")\n",
    "    color_idx = 0\n",
    "    colors_dict = {}\n",
    "    last_x = 0\n",
    "    already_annotated = False\n",
    "    for _, row in meas_500[meas_500[\"peak\"] == True].iterrows():\n",
    "        x = row[\"energy\"]\n",
    "        label = row[\"identified_isotope\"]\n",
    "        if label in colors_dict.keys():\n",
    "            color = colors_dict[label]\n",
    "            already_annotated = True\n",
    "        else:\n",
    "            color = colors[color_idx]\n",
    "            colors_dict[label] = color\n",
    "            color_idx += 1\n",
    "            already_annotated = False\n",
    "        if x - last_x < 100 and last_x > 0:\n",
    "            space = x * scaler\n",
    "        else:\n",
    "            space = 0\n",
    "\n",
    "        last_x = x\n",
    "        ax.vlines(\n",
    "            x=x,\n",
    "            ymin=0,\n",
    "            ymax=1_000_000,\n",
    "            color=color,\n",
    "            alpha=0.5,\n",
    "            linewidth=0.3,\n",
    "            linestyle=(0, (5, 5))\n",
    "        )\n",
    "        if already_annotated is True:\n",
    "            pass\n",
    "        else:\n",
    "            ax.annotate(\n",
    "                text=label,\n",
    "                xy=(x, limitation),  # point to peak (start of arrow)\n",
    "                xytext=(x + space, limitation * 1.15),  # label position (to the right and above)\n",
    "                textcoords='data',\n",
    "                fontsize=11,\n",
    "                color=color,\n",
    "                # rotation=90,\n",
    "                rotation=90,\n",
    "                zorder=0,\n",
    "                ha='left',\n",
    "                va='bottom',\n",
    "                arrowprops=dict(\n",
    "                    arrowstyle='-',\n",
    "                    connectionstyle='arc,angleA=90,angleB=0,rad=0,armA=10,armB=0',\n",
    "                    color=color,\n",
    "                    linewidth=0.3,\n",
    "                    zorder=100,\n",
    "                    linestyle=(0, (5, 5)),\n",
    "                    alpha=0.5\n",
    "                )\n",
    "            )\n",
    "\n",
    "    ax.text(1.02, 0.6, title,\n",
    "        transform=ax.transAxes,\n",
    "        rotation=270,\n",
    "        va='center',\n",
    "        zorder=2000,\n",
    "        ha='left',\n",
    "        fontsize=12)\n",
    "    ax.set_ylim(0, limitation)\n",
    "    ax.set_xlim(0, 2000)\n",
    "    # if idx == 4:\n",
    "    #     ax.set_xlabel(\"Energie [keV]\", size=14)\n",
    "    # if idx == 0 or idx == 3:\n",
    "    #     ax.set_ylabel(\"Zählwert\", size=14)\n",
    "    ax.tick_params(axis='x', labelsize=12, bottom=True)\n",
    "    ax.tick_params(axis='y', labelsize=12, left=True)\n",
    "    ax.grid(False)\n",
    "    # ax = ax.gca()\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    # ax.spines[\"left\"].set_visible(False)\n",
    "    # ax.spines[\"bottom\"].set_visible(False)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(10, 5), sharex=True)\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "good_examples = [0, 20, 40, 58, 75, 109]\n",
    "axs = axs.flatten()  # now axs is a 1D array\n",
    "# one_meas_synthetics =gpi.API().synthetics_for_meas([date])\n",
    "\n",
    "fig.text(0.5, 0.0, \"Energie [keV]\", size=14, ha='center')\n",
    "fig.text(0.05, 0.5, \"Zählwert\", size=14, va='center', rotation='vertical')\n",
    "limitations = [50, 300, 500, 1000, 60, 2000]\n",
    "scaler = [10, 10 ,10, 0.0 ,0.2 ,10]\n",
    "titles = [\"(A) 1 Nuklid pro Messung\", \"(B) 2 Nuklide pro Messung\", \"(C) 3 Nuklide pro Messung\",\n",
    "          \"(D) 4 Nuklide pro Messung\", \"(E) 5 Nuklide pro Messung\", \"(F) 6 Nuklide pro Messung\"]\n",
    "for idx, sample in enumerate(good_examples):\n",
    "    date = re_keys[sample]\n",
    "    limitation = limitations[idx]\n",
    "    one_meas_processed_measurement = validation_set.loc[validation_set[\"datetime\"] == date]\n",
    "    one_meas_processed_measurement[\"identified_isotope\"] = one_meas_processed_measurement[\"identified_isotope\"].apply(\n",
    "        format_isotope)\n",
    "    make_subplot(axs[idx], one_meas_processed_measurement, limitation, idx, titles[idx], scaler[idx])\n",
    "\n",
    "plt.savefig(\"plots/background_meas_example555.pdf\", bbox_inches='tight')\n",
    "# 3406,5\n",
    "# 54512,64\n",
    "# 8449,22\n",
    "# 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for key in re_keys[8:9]:\n",
    "    filtered_df = validation_set.loc[validation_set[\"datetime\"] == key].reset_index(drop=True)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=filtered_df[\"energy\"],\n",
    "        y=filtered_df[\"count\"],\n",
    "        mode='lines',\n",
    "        name=str(key),\n",
    "        line=dict(color='black')\n",
    "    ))\n",
    "    identified_peaks = filtered_df.loc[filtered_df[\"peak\"] == True].reset_index(drop=True)\n",
    "    unique_isotopes = identified_peaks[\"identified_isotope\"].unique()\n",
    "    for iso in unique_isotopes:\n",
    "        filtered_iso = identified_peaks.loc[identified_peaks[\"identified_isotope\"] == iso].reset_index(drop=True)\n",
    "        fig.add_trace(go.Scatter(x=filtered_iso[\"energy\"], y=filtered_iso[\"count\"],\n",
    "                             mode='markers', name=iso,\n",
    "                             marker=dict(color='red', size=8, symbol='circle')))\n",
    "\n",
    "fig.update_layout(height=1000, title=\"Signal mit Peaks\")\n",
    "fig.update_xaxes(title=\"Energie [keV]\")\n",
    "fig.update_yaxes(title=\"Zählwert\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "\n",
    "training_min_loss_x = data_mic_mac_loss[\"training_macro_loss\"].max()\n",
    "training_min_loss_y = data_mic_mac_loss.loc[data_mic_mac_loss[\"training_macro_loss\"] == training_min_loss_x][\"epoch\"].values[0]\n",
    "\n",
    "validation_min_loss_x = data_mic_mac_loss[\"validation_macro_loss\"].max()\n",
    "validation_min_loss_y = data_mic_mac_loss.loc[data_mic_mac_loss[\"validation_macro_loss\"] == validation_min_loss_x][\"epoch\"].values[0]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(data_mic_mac_loss[\"epoch\"], data_mic_mac_loss[\"training_macro_loss\"], color=\"black\",\n",
    "         label=\"training_macro_loss\")\n",
    "\n",
    "plt.plot(data_mic_mac_loss[\"epoch\"], data_mic_mac_loss[\"validation_macro_loss\"], color=\"red\",\n",
    "         label=\"validation_macro_loss\")\n",
    "plt.annotate(f'MAX(Macro-AUC) Training = {round(training_min_loss_x, 2)}',\n",
    "             ha='center', va='bottom',\n",
    "             size='large',\n",
    "             xytext=(training_min_loss_y, 1), xy=(training_min_loss_y, training_min_loss_x), arrowprops={'facecolor': 'darkgrey'}, alpha=0.5)\n",
    "\n",
    "plt.annotate(f'MAX(Macro-AUC) Validierung = {round(validation_min_loss_x, 2)}',\n",
    "             ha='center', va='bottom',\n",
    "             size='large',\n",
    "             xytext=(validation_min_loss_y, 1), xy=(validation_min_loss_y, validation_min_loss_x), arrowprops={'facecolor': 'darkgrey'}, alpha=0.5)\n",
    "plt.ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = data_auc.loc[data_auc[\"epoch\"] == validation_min_loss_y]\n",
    "def format_isotope(isotope):\n",
    "    match = re.match(r\"([a-zA-Z]+)(\\d+)\", isotope)\n",
    "    if match:\n",
    "        element, mass = match.groups()\n",
    "        validation_auc = aucs.loc[aucs[\"nuclide\"] == isotope].reset_index(drop=True)[\"validation_auc\"][0]\n",
    "        training_uac = aucs.loc[aucs[\"nuclide\"] == isotope].reset_index(drop=True)[\"training_auc\"][0]\n",
    "        return f\"$^{{{mass}}}{element.capitalize()}$\\nAUC-Training={round(training_uac, 2)}\\nAUC-Validation={round(validation_auc, 2)}\"\n",
    "    else:\n",
    "        return isotope  # fallback if format doesn't match\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "filtered_data = data_tpr_fpr[data_tpr_fpr[\"epoch\"] == validation_min_loss_y].reset_index(drop=True)\n",
    "filtered_data[\"nuclide\"] = filtered_data[\"nuclide\"].apply(format_isotope)\n",
    "# filtered_data[\"validation_fpr\"] = filtered_data[\"validation_fpr\"] * filtered_data.index\n",
    "rel = sns.relplot(filtered_data, x=\"validation_fpr\", y=\"validation_tpr\", hue=\"nuclide\", kind=\"line\", drawstyle=\"steps-pre\", palette=sns.color_palette())\n",
    "ax = rel.ax\n",
    "ax.plot([0, 1], [0, 1], color=\"lightgrey\", linestyle=\"--\", linewidth=2, label=\"Basislinie\")\n",
    "ax.set_xlabel(\"False Positive Rate (FPR)\", size=14)\n",
    "ax.set_ylabel(\"True Positive Rate (TPR)\", size=14)\n",
    "ax.tick_params(axis='x', labelsize=12, bottom=True)\n",
    "ax.tick_params(axis='y', labelsize=12, left=True)\n",
    "ax.grid(True, alpha=0.2)\n",
    "sns.move_legend(rel,\n",
    "                loc=\"lower center\",\n",
    "                bbox_to_anchor=(0.5, 1.02),\n",
    "                borderaxespad=0,\n",
    "                title=\"\",\n",
    "                ncol=3,\n",
    "                frameon=False)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "rel._legend.remove()\n",
    "ax.legend(handles, labels, loc=\"lower center\", bbox_to_anchor=(0.5, 1.02), ncol=3, frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.loc[filtered_data[\"nuclide\"].str.contains(\"Co\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.measurements.api as mpi\n",
    "splitted_keys = mpi.API().re_splitted_keys()\n",
    "validation_keys = splitted_keys.loc[splitted_keys[\"type\"] == \"cnn_validation\"].reset_index(drop=True)[\"datetime\"].tolist()\n",
    "validation_measurements = ppi.API().re_measurement(validation_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_cnn_pm = Training(use_processed_synthetics=bool(\n",
    "                load_config()[\"cnn\"][\"use_processed_synthetics\"]\n",
    "            ),\n",
    "            use_processed_measuremnets=bool(\n",
    "                load_config()[\"cnn\"][\"use_processed_measurements\"],\n",
    "            ),\n",
    "            use_re_processed_data=True).validation_cnn_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_mlb = validation_cnn_pm.fitted_mlb\n",
    "fitted_mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "isos_ind = pd.DataFrame([validation_cnn_pm.labels_by_datetime]).T.reset_index()\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "def count_ones(val):\n",
    "    # Remove the 'array(' and the final ')'\n",
    "    arr = val # turns string into actual list\n",
    "    return sum(arr[0])  # count 1s in the inner list\n",
    "\n",
    "isos_ind[\"ones_count\"] = isos_ind[0].apply(count_ones)\n",
    "# isos_ind.gropby(\"ones_count\").count(numeric_only=True)\n",
    "isos_ind.groupby(\"ones_count\")[\"index\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "validation_cnn_pm_loader = DataLoader(\n",
    "validation_cnn_pm, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = validation_cnn_pm.__getitem__(10)\n",
    "test = item[0].float().to(\"cpu\").unsqueeze(0).unsqueeze(0)\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "item[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_cnn_pm.__getitem__(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlb_classes\n",
    "model.eval()\n",
    "for i in range(30):\n",
    "    item = validation_cnn_pm.__getitem__(i)\n",
    "    test = item[0].float().to(\"cpu\").unsqueeze(0).unsqueeze(0)\n",
    "    output = model(test)\n",
    "    # print(output)\n",
    "    print(torch.sigmoid(output))\n",
    "    # print(item[1])\n",
    "    print(item[0])\n",
    "    print(item[2])\n",
    "    print(item[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "item[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 8160 * 0.34507313512321336, 0.34507313512321336)\n",
    "plt.plot(x, test[0].T)\n",
    "\n",
    "plt.ylim(0,0.1)\n",
    "plt.xlim(0,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([item[2].T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks, savgol_filter\n",
    "target = torch.tensor([item[2].T])\n",
    "\n",
    "# Your model's input\n",
    "test.requires_grad_()  # test shape: [1, C, H, W]\n",
    "output = model(test)   # output shape: [1, num_classes]\n",
    "\n",
    "# Your ground truth labels (binary, multi-label)\n",
    "\n",
    "positive_classes = (target[0] == 1).nonzero(as_tuple=True)[0]  # tensor([1, 7])\n",
    "\n",
    "for class_idx in positive_classes:\n",
    "    model.zero_grad()\n",
    "    print(class_idx)\n",
    "\n",
    "    # Grab a **scalar** logit for the current class\n",
    "    class_score = output[0, class_idx]  # this is a scalar\n",
    "    class_score.backward(retain_graph=True)\n",
    "\n",
    "    # Create saliency map from gradients\n",
    "    saliency = test.grad.data.abs()\n",
    "    saliency, _ = saliency.max(dim=1)  # reduce over channels\n",
    "    saliency_map = saliency.squeeze().cpu().numpy()\n",
    "\n",
    "    # Optional: normalize saliency for display\n",
    "    saliency_map -= saliency_map.min()\n",
    "    saliency_map /= saliency_map.max() + 1e-8\n",
    "\n",
    "    # Plot it\n",
    "    plt.plot(x, savgol_filter(saliency_map, window_length=100, polyorder=1))\n",
    "    plt.title(f\"Saliency Map for Class {class_idx.item()}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Clear gradient for next class\n",
    "    test.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Your model\n",
    "model.eval()\n",
    "background = []\n",
    "for i in range(30):\n",
    "    item = validation_cnn_pm.__getitem__(i)\n",
    "    test = item[0].float().to(\"cpu\").unsqueeze(0).unsqueeze(0)\n",
    "    background.append(test)\n",
    "    output = model(test)\n",
    "    # print(output)\n",
    "    print(torch.sigmoid(output))\n",
    "    # print(item[1])\n",
    "    print(item[0])\n",
    "    print(item[2])\n",
    "    print(item[1])\n",
    "background = torch.cat(background, dim=0)\n",
    "# SHAP explainer\n",
    "explainer = shap.DeepExplainer(model, background)\n",
    "\n",
    "# Explain one or more samples\n",
    "# shap_values = explainer.shap_values(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_cnn_pm.__getitem__(31)[0].float().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "background[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(validation_cnn_pm_loader))[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "class ModelWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model.eval().to(\"cuda\")\n",
    "\n",
    "    def __call__(self, x_numpy):\n",
    "        x_tensor = torch.from_numpy(x_numpy).float().unsqueeze(1).to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            return torch.sigmoid(self.model(x_tensor)).cpu().numpy()\n",
    "\n",
    "# Load a batch\n",
    "validation_cnn_pm_loader = DataLoader(validation_cnn_pm, batch_size=50, shuffle=True)\n",
    "batch = next(iter(validation_cnn_pm_loader))[0]  # shape: [50, 8160]\n",
    "\n",
    "# Background and test sample\n",
    "background = batch[:20].numpy()           # shape: [20, 8160]\n",
    "test_sample = batch[21].unsqueeze(0).numpy()  # shape: [1, 8160]\n",
    "\n",
    "# Wrap the model\n",
    "wrapped_model = ModelWrapper(model)\n",
    "\n",
    "# SHAP explainer (Partition works well for tabular or 1D)\n",
    "explainer = shap.Explainer(wrapped_model, background, algorithm=\"partition\")\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values = explainer(test_sample)  # returns shap.Explanation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract SHAP values for class 0\n",
    "shap_vals_class0 = shap_values.values[0, :, 0]  # shape: (8160,)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 4))\n",
    "x = np.arange(0, 8160 * 0.34507313512321336, 0.34507313512321336)\n",
    "plt.plot(x, shap_vals_class0)\n",
    "plt.title(\"SHAP values for class 1\")\n",
    "plt.xlabel(\"Feature index\")\n",
    "plt.ylabel(\"SHAP value\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
