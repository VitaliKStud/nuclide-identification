{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import random\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import matplotlib\n",
    "import matplotlib.colors as mcolors\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "from src.peaks.finder import PeakFinder\n",
    "\n",
    "import mlflow\n",
    "from config.loader import load_config\n",
    "import os\n",
    "\n",
    "import src.measurements.api as mpi\n",
    "import src.generator.api as gpi\n",
    "import src.peaks.api as ppi\n",
    "import src.statistics.api as spi\n",
    "plt.rcParams['text.usetex'] = True\n",
    "from src.cnn.training import Training\n",
    "import json\n",
    "from src.cnn.dataset import MeasurementTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "from config.loader import load_config\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = load_config()[\"minio\"][\"AWS_ACCESS_KEY_ID\"]\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = load_config()[\"minio\"][\"AWS_SECRET_ACCESS_KEY\"]\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = load_config()[\"minio\"][\"MLFLOW_S3_ENDPOINT_URL\"]\n",
    "model_uri = load_config()[\"mlflow\"][\"uri\"]\n",
    "model_name = \"CNN_CPU\"\n",
    "model_version = \"latest\"\n",
    "mlflow.set_tracking_uri(uri=model_uri)\n",
    "model = mlflow.pytorch.load_model(f\"models:/{model_name}/{model_version}\").to(\"cpu\")\n",
    "\n",
    "client = mlflow.tracking.MlflowClient(\n",
    "    tracking_uri=load_config()[\"mlflow\"][\"uri\"]\n",
    ")\n",
    "run_id = client.get_latest_versions(\"CNN_CPU\")[0].run_id\n",
    "run = client.get_run(run_id)\n",
    "client.download_artifacts(run_id=run_id, path=\"artifacts.json\", dst_path=\"tmp\")\n",
    "mlb_classes = run.data.params[\"mlb_classes\"].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_macro_loss = client.get_metric_history(run_id=run_id, key=\"training_macro_loss\")\n",
    "training_micro_loss = client.get_metric_history(run_id=run_id, key=\"training_micro_loss\")\n",
    "training_mac_loss = []\n",
    "training_mic_loss = []\n",
    "for i in range(len(training_macro_loss)):\n",
    "    macro_loss = training_macro_loss[i].value\n",
    "    training_mac_loss.append(macro_loss)\n",
    "    micro_loss = training_micro_loss[i].value\n",
    "    training_mic_loss.append(micro_loss)\n",
    "\n",
    "data_mic_mac_loss = pd.DataFrame([training_mac_loss, training_mic_loss])\n",
    "data_mic_mac_loss = data_mic_mac_loss.T.rename(columns={0:\"training_macro_loss\", 1:\"training_micro_loss\"})\n",
    "data_mic_mac_loss[\"epoch\"] = data_mic_mac_loss.index\n",
    "data_mic_mac_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tmp/artifacts.json\") as f:\n",
    "    artifacts = json.load(f)\n",
    "# dict_keys(['used_keys', 'training_tpr', 'training_fpr', 'training_auc', 'validation_tpr', 'validation_fpr', 'validation_auc'])\n",
    "\n",
    "data_tpr_fpr = pd.DataFrame()\n",
    "\n",
    "for idx in range(len(artifacts[\"training_tpr\"])):\n",
    "    for nuclide in artifacts[\"training_tpr\"][idx].keys():\n",
    "        nuclide_df = pd.DataFrame(artifacts[\"training_tpr\"][idx][nuclide], columns=[\"training_tpr\"])\n",
    "        nuclide_df[\"training_fpr\"] = artifacts[\"training_fpr\"][idx][nuclide]\n",
    "        nuclide_df[\"nuclide\"] = nuclide\n",
    "        nuclide_df[\"epoch\"] = idx\n",
    "        data_tpr_fpr = pd.concat([data_tpr_fpr, nuclide_df], axis=0)\n",
    "data_tpr_fpr = data_tpr_fpr.reset_index(drop=True)\n",
    "\n",
    "data_auc = pd.DataFrame()\n",
    "\n",
    "for idx in range(len(artifacts[\"training_auc\"])):\n",
    "    for nuclide in artifacts[\"training_auc\"][idx].keys():\n",
    "        nuclide_df = pd.DataFrame([artifacts[\"training_auc\"][idx][nuclide]], columns=[\"training_auc\"])\n",
    "        nuclide_df[\"nuclide\"] = nuclide\n",
    "        nuclide_df[\"epoch\"] = idx\n",
    "        data_auc = pd.concat([data_auc, nuclide_df], axis=0)\n",
    "data_auc = data_auc.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=data_auc, x=\"epoch\", y=\"training_auc\", hue=\"nuclide\", kind=\"line\")\n",
    "plt.plot(data_mic_mac_loss[\"epoch\"], data_mic_mac_loss[\"training_macro_loss\"], color=\"black\", label=\"training_macro_loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data_tpr_fpr, x=\"training_fpr\", y=\"training_tpr\", hue=\"epoch\", col=\"nuclide\", col_wrap=3, kind=\"line\",\n",
    "            drawstyle=\"steps-pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.measurements.api as mpi\n",
    "splitted_keys = mpi.API().re_splitted_keys()\n",
    "validation_keys = splitted_keys.loc[splitted_keys[\"type\"] == \"cnn_validation\"].reset_index(drop=True)[\"datetime\"].tolist()\n",
    "validation_measurements = ppi.API().re_measurement(validation_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_cnn_pm = Training(use_processed_synthetics=bool(\n",
    "                load_config()[\"cnn\"][\"use_processed_synthetics\"]\n",
    "            ),\n",
    "            use_processed_measuremnets=bool(\n",
    "                load_config()[\"cnn\"][\"use_processed_measurements\"],\n",
    "            ),\n",
    "            use_re_processed_data=True).validation_cnn_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_measurements[\"identified_isotope\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = validation_cnn_pm.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_mlb = validation_cnn_pm.fitted_mlb\n",
    "fitted_mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "isos_ind = pd.DataFrame([validation_cnn_pm.labels_by_datetime]).T.reset_index()\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "def count_ones(val):\n",
    "    # Remove the 'array(' and the final ')'\n",
    "    arr = val # turns string into actual list\n",
    "    return sum(arr[0])  # count 1s in the inner list\n",
    "\n",
    "isos_ind[\"ones_count\"] = isos_ind[0].apply(count_ones)\n",
    "# isos_ind.gropby(\"ones_count\").count(numeric_only=True)\n",
    "isos_ind.groupby(\"ones_count\")[\"index\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "validation_cnn_pm_loader = DataLoader(\n",
    "validation_cnn_pm, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = validation_cnn_pm.__getitem__(10)\n",
    "test = item[0].float().to(\"cpu\").unsqueeze(0).unsqueeze(0)\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "item[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_cnn_pm.__getitem__(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlb_classes\n",
    "model.eval()\n",
    "for i in range(10):\n",
    "    item = validation_cnn_pm.__getitem__(i)\n",
    "    test = item[0].float().to(\"cpu\").unsqueeze(0).unsqueeze(0)\n",
    "    output = model(test)\n",
    "    # print(output)\n",
    "    print(torch.sigmoid(output))\n",
    "    # print(item[1])\n",
    "    print(item[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
