{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.peaks.api as ppi\n",
    "from src.peaks.refinder import RePeakFinder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import src.vae.api as vpi\n",
    "import random\n",
    "import src.generator.api as gpi\n",
    "\n",
    "# dates = vpi.API().unique_dates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_keys = vpi.API().unique_dates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(synthetic_keys)\n",
    "synthetics = gpi.API().synthetics(keys=synthetic_keys[0:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ppi.API().unique_dates()\n",
    "meas = ppi.API().measurement(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = meas.loc[meas[\"energy\"] >= 500].groupby(\"datetime\").std(numeric_only=True)[\"count\"]\n",
    "\n",
    "# Step 2: Compute desired percentiles\n",
    "percentiles = stds.quantile([0.0, 0.25, 0.5, 0.75, 0.99])\n",
    "\n",
    "# Step 3: Find datetimes closest to each percentile\n",
    "closest_datetimes = {}\n",
    "for q, target in percentiles.items():\n",
    "    closest = (stds - target).abs().idxmin()\n",
    "    closest_datetimes[q] = closest\n",
    "\n",
    "# Optional: Show result\n",
    "for q, dt in closest_datetimes.items():\n",
    "    print(f\"{int(q * 100)}th percentile → {dt} (std ≈ {stds[dt]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Group by datetime and compute std\n",
    "stds = meas.loc[(meas[\"energy\"] < 500) & (meas[\"energy\"] > 20)].groupby(\"datetime\").std(numeric_only=True)[\"count\"]\n",
    "\n",
    "# Step 2: Compute desired percentiles\n",
    "percentiles = stds.quantile([0.0, 0.25, 0.5, 0.75, 0.99])\n",
    "\n",
    "# Step 3: Find datetimes closest to each percentile\n",
    "closest_datetimes = {}\n",
    "for q, target in percentiles.items():\n",
    "    closest = (stds - target).abs().idxmin()\n",
    "    closest_datetimes[q] = closest\n",
    "\n",
    "# Optional: Show result\n",
    "for q, dt in closest_datetimes.items():\n",
    "    print(f\"{int(q * 100)}th percentile → {dt} (std ≈ {stds[dt]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Group by datetime and compute std\n",
    "stds = synthetics.loc[synthetics[\"energy\"] >= 500].groupby(\"datetime\").std(numeric_only=True)[\"count\"]\n",
    "\n",
    "# Step 2: Compute desired percentiles\n",
    "percentiles = stds.quantile([0.0, 0.25, 0.5, 0.75, 0.99])\n",
    "\n",
    "# Step 3: Find datetimes closest to each percentile\n",
    "closest_datetimes = {}\n",
    "for q, target in percentiles.items():\n",
    "    closest = (stds - target).abs().idxmin()\n",
    "    closest_datetimes[q] = closest\n",
    "\n",
    "# Optional: Show result\n",
    "for q, dt in closest_datetimes.items():\n",
    "    print(f\"{int(q * 100)}th percentile → {dt} (std ≈ {stds[dt]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Group by datetime and compute std\n",
    "stds = \\\n",
    "synthetics.loc[(synthetics[\"energy\"] < 500) & (synthetics[\"energy\"] > 20)].groupby(\"datetime\").std(numeric_only=True)[\n",
    "    \"count\"]\n",
    "\n",
    "# Step 2: Compute desired percentiles\n",
    "percentiles = stds.quantile([0.0, 0.25, 0.5, 0.75, 0.99])\n",
    "\n",
    "# Step 3: Find datetimes closest to each percentile\n",
    "closest_datetimes = {}\n",
    "for q, target in percentiles.items():\n",
    "    closest = (stds - target).abs().idxmin()\n",
    "    closest_datetimes[q] = closest\n",
    "\n",
    "# Optional: Show result\n",
    "for q, dt in closest_datetimes.items():\n",
    "    print(f\"{int(q * 100)}th percentile → {dt} (std ≈ {stds[dt]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates = ppi.API().unique_dates()\n",
    "# meas = ppi.API().measurement([dates[500]])\n",
    "\n",
    "\n",
    "to_analze = synthetics.loc[synthetics[\"datetime\"] == \"v53_synthetic_1312_2019-11-27 08:58:52\"].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "res = RePeakFinder(\n",
    "    selected_date=None,\n",
    "    data=to_analze[[\"datetime\", \"energy\", \"count\"]],\n",
    "    meta=None,\n",
    "    schema=\"re_processed_synthetics\",\n",
    "    matching_ratio=0,\n",
    "    interpolate_energy=False,\n",
    "    measurement_peaks_prefix=\"\"\n",
    ").process_spectrum(return_detailed_view=False)\n",
    "res[\"counts_cleaned\"] = res[\"count\"] - res[\"background\"]\n",
    "peaks = res.loc[res[\"peak\"] == True]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Raw counts\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=res[\"energy\"],\n",
    "    y=res[\"count\"],\n",
    "    mode='lines',\n",
    "    name='Raw Counts'\n",
    "))\n",
    "\n",
    "# Peak positions\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=peaks[\"energy\"],\n",
    "    y=peaks[\"count\"],\n",
    "    mode='markers',\n",
    "    text=peaks[\"identified_isotope\"],\n",
    "    marker=dict(color='black', size=8, symbol='x')\n",
    "))\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "y_smooth = savgol_filter(res[\"count\"].to_numpy(), window_length=8, polyorder=1)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=res[\"energy\"],\n",
    "    y=y_smooth,\n",
    "    mode='lines',\n",
    "    name='Raw Counts'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Peak Detection Overlay\",\n",
    "    xaxis_title=\"Energy\",\n",
    "    yaxis_title=\"Counts\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELL FÜR > 500keV\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# real_greater500\n",
    "x_real_greater500 = np.array([4, 1, 1.4, 0.2, 0.02])\n",
    "y_real_greater500 = np.array([0.3507, 2.5214, 5.8117, 18.8154, 2417.0879])\n",
    "\n",
    "# real_less500\n",
    "x_real_less500 = np.array([0.2, 0.7, 0.8, 0.6, 0.1])\n",
    "y_real_less500 = np.array([1.21424, 10.7187, 15.6976, 48.2542, 11026.2624])\n",
    "\n",
    "# synthetic_greater500\n",
    "x_synthetic_greater500 = np.array([0.2, 0.4, 0.7, 0.2, 0.1])\n",
    "y_synthetic_greater500 = np.array([0.1161, 6.0469, 14.7788, 36.3063, 5596.2659])\n",
    "\n",
    "# synthetic_less500\n",
    "x_synthetic_less500 = np.array([0.01, 0.086, 0.1, 0.4, 1])\n",
    "y_synthetic_less500 = np.array([0.3163, 19.2846, 53.5015, 146.7614, 31982.5049])\n",
    "\n",
    "def create_model(x, y):\n",
    "    def exp_model(x, a, b):\n",
    "        return a * np.exp(-b * x)\n",
    "\n",
    "    # Fit\n",
    "    popt, _ = curve_fit(exp_model, x, y, p0=(2000, 2), maxfev=20000)\n",
    "    a, b = popt\n",
    "\n",
    "    # Vorhersagekurve\n",
    "    x_fit = np.linspace(0, 1, 200)\n",
    "    y_fit = exp_model(x_fit, a, b)\n",
    "\n",
    "    # Plot\n",
    "    plt.scatter(x, y, label=\"Original Data\", color=\"red\")\n",
    "    plt.plot(x_fit, y_fit, label=f\"Fit: y = {a:.1f} * exp(-{b:.2f} * x)\", color=\"blue\")\n",
    "    plt.xlabel(\"std\")\n",
    "    plt.ylabel(\"Threshold\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.ylim(-100,13000)\n",
    "    plt.title(\"Exponentielles Modell für Threshold vs. std\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "create_model(x_synthetic_greater500, y_synthetic_greater500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = 7\n",
    "x = np.array([0.2, 0.4, 0.7, 0.2, 0.1]) # _greater500\n",
    "y = np.array([0.1161, 6.0469, 14.7788, 36.3063, 5596.2659]) # _greater500\n",
    "\n",
    "if std > y[-1]:\n",
    "    estimated_prominance = x[-1]\n",
    "if std < y[0]:\n",
    "    estimated_prominance = x[0]\n",
    "\n",
    "else:\n",
    "    min_prominence = x[std >= y][-1]\n",
    "    max_prominence = x[std <= y][0]\n",
    "    estimated_prominance = np.mean([min_prominence, max_prominence])\n",
    "\n",
    "print(estimated_prominance)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
